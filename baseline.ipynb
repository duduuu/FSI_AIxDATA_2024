{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalous Financial Transaction Detection\n",
    "\n",
    "본 대회의 과제는 금융 거래 데이터에서 **이상 거래를 탐지하는 기능**을 개선하고 활용도를 높이는 분류 AI모델을 개발하는 것입니다. \n",
    "\n",
    "특히, 클래스 불균형 문제를 해결하기 위해 오픈소스 생성형 AI 모델을 활용하여 부족한 클래스의 데이터를 보완하고, 이를 통해 분류 모델의 성능을 향상시키는 것이 핵심 목표입니다. \n",
    "\n",
    "이러한 접근을 통해 금융보안에 특화된 데이터 분석 및 활용 역량을 강화하여 전문 인력을 양성하고, 금융권의 AI 활용 어려움에 따른 해결 방안을 함께 모색하며 금융 산업의 AI 활용 활성화를 지원하는 것을 목표로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성 관련\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# 데이터 처리 및 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 머신러닝 전처리\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# 머신러닝 모델\n",
    "import xgboost as xgb\n",
    "\n",
    "# 합성 데이터 생성\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# To ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 생성 🏭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_csv(\"./train.csv\")\n",
    "test_all = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_all.drop(columns=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Fraud_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(*) 리더보드 산식 중 생성데이터의 익명성(TCAP)채점을 위해 각 클래스 별로 1000개의 생성데이터가 반드시 필요합니다.\n",
    "(*) 본 베이스 라인에서는 \"Fraud_Type\" 13종류에 대해 1000개씩 , 총 13,000개의 데이터를 생성할 예정입니다.\n",
    "(*) 분류 모델 성능 개선을 위해 생성 데이터를 활용하는 것에는 생성 데이터의 Row 개수에 제한이 없습니다. 단, 리더보드 평가를 위해 제출을 하는 생성 데이터 프레임은 익명성(TCAP) 평가를 위함이며, 위의 조건을 갖춘 생성 데이터를 제출해야합니다.\n",
    "'''\n",
    "N_CLS_PER_GEN = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이상치 처리 함수\n",
    "def handle_outliers(series, n_std=3):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    z_scores = np.abs(stats.zscore(series))\n",
    "    return series.mask(z_scores > n_std, mean)\n",
    "\n",
    "# Time_difference 컬럼을 총 초로 변환 및 이상치 처리\n",
    "train['Time_difference_seconds'] = pd.to_timedelta(train['Time_difference']).dt.total_seconds()\n",
    "train['Time_difference_seconds'] = handle_outliers(train['Time_difference_seconds'])\n",
    "\n",
    "\n",
    "# 모든 Fraud_Type 목록 생성 (m 포함)\n",
    "fraud_types = train['Fraud_Type'].unique()\n",
    "\n",
    "# 모든 합성 데이터를 저장할 DataFrame 초기화\n",
    "all_synthetic_data = pd.DataFrame()\n",
    "\n",
    "N_SAMPLE = 100\n",
    "\n",
    "# 각 Fraud_Type에 대해 합성 데이터 생성 및 저장\n",
    "for fraud_type in tqdm(fraud_types):\n",
    "    \n",
    "    # 해당 Fraud_Type에 대한 서브셋 생성\n",
    "    subset = train[train[\"Fraud_Type\"] == fraud_type]\n",
    "\n",
    "    # 모든 Fraud_Type에 대해 100개씩 샘플링\n",
    "    subset = subset.sample(n=N_SAMPLE, random_state=42)\n",
    "    \n",
    "    # Time_difference 열 제외 (초 단위로 변환된 컬럼만 사용)\n",
    "    subset = subset.drop('Time_difference', axis=1)\n",
    "    \n",
    "    # 메타데이터 생성 및 모델 학습\n",
    "    metadata = SingleTableMetadata()\n",
    "\n",
    "    metadata.detect_from_dataframe(subset)\n",
    "    metadata.set_primary_key(None)\n",
    "\n",
    "    # 데이터 타입 설정\n",
    "    column_sdtypes = {\n",
    "        'Account_initial_balance': 'numerical',\n",
    "        'Account_balance': 'numerical',\n",
    "        'Customer_identification_number': 'categorical',  \n",
    "        'Customer_personal_identifier': 'categorical',\n",
    "        'Account_account_number': 'categorical',\n",
    "        'IP_Address': 'ipv4_address',  \n",
    "        'Location': 'categorical',\n",
    "        'Recipient_Account_Number': 'categorical',\n",
    "        'Fraud_Type': 'categorical',\n",
    "        'Time_difference_seconds': 'numerical',\n",
    "        'Customer_Birthyear': 'numerical'\n",
    "    }\n",
    "\n",
    "    # 각 컬럼에 대해 데이터 타입 설정\n",
    "    for column, sdtype in column_sdtypes.items():\n",
    "        metadata.update_column(\n",
    "            column_name=column,\n",
    "            sdtype=sdtype\n",
    "        )\n",
    "        \n",
    "    synthesizer = CTGANSynthesizer(\n",
    "                            metadata,\n",
    "                            epochs=100\n",
    "                        )\n",
    "    synthesizer.fit(subset)\n",
    "\n",
    "    synthetic_subset = synthesizer.sample(num_rows=N_CLS_PER_GEN)\n",
    "    \n",
    "    # 생성된 Time_difference_seconds의 이상치 처리\n",
    "    synthetic_subset['Time_difference_seconds'] = handle_outliers(synthetic_subset['Time_difference_seconds'])\n",
    "    \n",
    "    # Time_difference_seconds를 다시 timedelta로 변환\n",
    "    synthetic_subset['Time_difference'] = pd.to_timedelta(synthetic_subset['Time_difference_seconds'], unit='s')\n",
    "    \n",
    "    # Time_difference_seconds 컬럼 제거\n",
    "    synthetic_subset = synthetic_subset.drop('Time_difference_seconds', axis=1)\n",
    "    \n",
    "    # 생성된 데이터를 all_synthetic_data에 추가\n",
    "    all_synthetic_data = pd.concat([all_synthetic_data, synthetic_subset], ignore_index=True)\n",
    "# 최종 결과 확인\n",
    "print(\"\\nFinal All Synthetic Data Shape:\", all_synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본 데이터와 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_train = train_all.drop(columns=\"ID\")\n",
    "train_total = pd.concat([origin_train, all_synthetic_data])\n",
    "train_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 1 : Select x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_total.drop(columns=['Fraud_Type'])\n",
    "train_y = train_total['Fraud_Type']\n",
    "\n",
    "test_x = test_all.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 2 : 범주형 변수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_subclass = LabelEncoder()\n",
    "train_y_encoded = le_subclass.fit_transform(train_y)\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x\n",
    "# 'Time_difference' 열을 문자열로 변환\n",
    "train_x['Time_difference'] = train_x['Time_difference'].astype(str)\n",
    "\n",
    "# 범주형 변수 인코딩\n",
    "categorical_columns = train_x.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# 훈련 데이터 인코딩\n",
    "train_x_encoded = train_x.copy()\n",
    "train_x_encoded[categorical_columns] = ordinal_encoder.fit_transform(train_x[categorical_columns])\n",
    "\n",
    "# 특성 순서 저장\n",
    "feature_order = train_x_encoded.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의 및 학습\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "model.fit(train_x_encoded[feature_order], train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 인코딩\n",
    "test_x_encoded = test_x.copy()\n",
    "test_x_encoded[categorical_columns] = ordinal_encoder.transform(test_x[categorical_columns])\n",
    "\n",
    "\n",
    "# 특성 순서 맞추기 및 데이터 타입 일치\n",
    "test_x_encoded = test_x_encoded[feature_order]\n",
    "for col in feature_order:\n",
    "    test_x_encoded[col] = test_x_encoded[col].astype(train_x_encoded[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "predictions = model.predict(test_x_encoded)\n",
    "predictions_label = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 예측 결과 제출 데이터프레임(DataFrame)\n",
    "# 분류 예측 결과 데이터프레임 파일명을 반드시 clf_submission.csv 로 지정해야합니다.\n",
    "clf_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "clf_submission[\"Fraud_Type\"] = predictions_label\n",
    "clf_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성 데이터 생성 결과 제출 데이터프레임(DataFrame)\n",
    "# 합성 데이터 생성 결과 데이터프레임 파일명을 반드시 syn_submission.csv 로 지정해야합니다.\n",
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(*) 저장 시 각 파일명을 반드시 확인해주세요.\n",
    "    1. 분류 예측 결과 데이터프레임 파일명 = clf_submission.csv\n",
    "    2. 합성 데이터 생성 결과 데이터프레임 파일명 = syn_submission.csv\n",
    "\n",
    "(*) 제출 파일(zip) 내에 두 개의 데이터프레임이 각각 위의 파일명으로 반드시 존재해야합니다.\n",
    "(*) 파일명을 일치시키지 않으면 채점이 불가능합니다.\n",
    "'''\n",
    "\n",
    "# 폴더 생성 및 작업 디렉토리 변경\n",
    "os.makedirs('./submission', exist_ok=True)\n",
    "os.chdir(\"./submission/\")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "clf_submission.to_csv('./clf_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "all_synthetic_data.to_csv('./syn_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "\n",
    "# ZIP 파일 생성 및 CSV 파일 추가\n",
    "with zipfile.ZipFile(\"../baseline_submission.zip\", 'w') as submission:\n",
    "    submission.write('clf_submission.csv')\n",
    "    submission.write('syn_submission.csv')\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gimin_py38",
   "language": "python",
   "name": "gimin_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
